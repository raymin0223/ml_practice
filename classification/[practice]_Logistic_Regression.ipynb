{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setting\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./data/logistic_regression.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "data.head()   # show the 5 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀 모델을 이용해 유저의 `Age` 정보만을 가지고 구매를 했는지(1), 혹은 안했는지(0)를 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'Age' and 'Purchased' data\n",
    "X = data['Age'].to_numpy(dtype=np.float32)\n",
    "y = data['Purchased'].to_numpy()\n",
    "\n",
    "# Normalize 'Age' value\n",
    "def normalize(X):\n",
    "    return X - X.mean()\n",
    "X = normalize(X)\n",
    "\n",
    "# Visualizing the dataset\n",
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [P.1] 데이터를 학습과 평가 데이터로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn library\n",
    "from ??? import ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the dataset\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the dataset\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구매를 한 사람들 중에서 나이가 많은 사람들이 많다는 경향성을 쉽게 파악 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [P.2] `Numpy` 패키지로만 로지스틱 회귀 모델 학습하기\n",
    "\n",
    "로지스틱 회귀 모델은 0부터 1 사이의 값을 출력해주는 S 모양의 로지스틱 함수로 만들어짐    \n",
    "따라서 출력값은 확률의 의미를 지니고 있으며, 0.5의 출력값을 기준으로 0과 1의 이진 클래스로 분류해주는 모델이 됨\n",
    "![logistic](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 모델은 최대 가능도 추정(maximum likelihood estimation)을 기반으로 모델을 학습함       \n",
    "이론 강의 시간동안 공부했던 내용이므로, 본 자료에서는 주어진 수식을 코드로 구현하는 연습만 진행\n",
    "\n",
    "**Logistic regression model** (w와 b 파라미터 두가지)\n",
    "\\begin{equation*}\n",
    "P(y_i=1|X_i) = \\frac{1}{1 + e^{-(wX_i + b)}}\n",
    "\\end{equation*}\n",
    "\n",
    "**Loss function**\n",
    "\\begin{equation*}\n",
    "-\\frac{1}{n} \\sum_{i=1}^n (y_i * log(P(y_i=1|X_i)) + (1 - y_i) * log(1 - P(y_i=1|X_i)))\n",
    "\\end{equation*}\n",
    "\n",
    "**Gradients calculation**\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^n ((P(y_i=1|X_i) - y_i) * X_i)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^n (P(y_i=1|X_i) - y_i)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setting\n",
    "epochs = 1000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Model weights and bias parameters\n",
    "w = 0.0\n",
    "b = 0.0\n",
    "\n",
    "# Perform Gradient Descent\n",
    "???\n",
    "    \n",
    "    \n",
    "#################################################\n",
    "######## Hint: use +, -, *, /, **, np.mean(), #######\n",
    "########           np.exp(), np.log() ###########\n",
    "    y_pred = ???   # Logistic regression\n",
    "    loss = ???   # Likelihood loss\n",
    "    \n",
    "    dw = ???   # gradients w.r.t to w\n",
    "    db = ???   # gradients w.r.t to b\n",
    "    \n",
    "    # Update model weights and bias\n",
    "    w = ???\n",
    "    b = ???\n",
    "    \n",
    "#################################################\n",
    "\n",
    "\n",
    "print('Trained model weights : %.4f' % w)\n",
    "print('Trained model bias : %.4f' % b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 결과를 시각화하면 다음과 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the trained linear regression model\n",
    "plt.scatter(X, y)   # scatter the original data\n",
    "y_pred = ???\n",
    "\n",
    "plt.scatter(X, y_pred, color='red')\n",
    "plt.axhline(y=0.5, color='orange', linestyle='--')   # show 0.5 threshold line\n",
    "\n",
    "# Accurate results are colored as orange\n",
    "index1 = (y == 0) * (y_pred < 0.5)\n",
    "index2 = (y == 1) * (y_pred > 0.5)\n",
    "index = index1 + index2\n",
    "plt.scatter(X[index], y[index], color='orange')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [P.3] `sklearn` 패키지를 통해서 로지스틱 회귀 모델 학습\n",
    "\n",
    "- [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) 모듈을 이용해 경사하강법을 쉽게 구현하고자 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ??? import ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_sklearn(X, y, max_iter, C):\n",
    "    X_2d = X.???\n",
    "    \n",
    "    reg = ???(penalty=???, \n",
    "             max_iter=???,\n",
    "             C=???, # inverse of regularization strength\n",
    "             tol=???,\n",
    "             solver=???,\n",
    "             random_state=42)\n",
    "    \n",
    "    reg.???\n",
    "    \n",
    "    w = reg.???\n",
    "    b = reg.???\n",
    "\n",
    "    print('Trained model weights : %.4f' % w)\n",
    "    print('Trained model bias : %.4f' % b)\n",
    "    \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "epochs = 1000\n",
    "C = 0.1\n",
    "\n",
    "model = gd_sklearn(X_train, y_train, max_iter=epochs, C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train loss\n",
    "X_train_2d = X_train.???\n",
    "y_pred = model.???\n",
    "\n",
    "train_loss = np.mean((y_train - y_pred)**2)\n",
    "print('Train Loss for LinearRegression model : %.4f' % train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.???\n",
    "b = model.???\n",
    "\n",
    "y_pred = ???\n",
    "y_pred = y_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the trained linear regression model\n",
    "plt.scatter(X_train, y_train)   # scatter the original data\n",
    "plt.scatter(X_train, y_pred, color='red')\n",
    "plt.axhline(y=0.5, color='orange', linestyle='--')   # show 0.5 threshold line\n",
    "\n",
    "# Accurate results are colored as orange\n",
    "index1 = (y_train == 0) * (y_pred < 0.5)\n",
    "index2 = (y_train == 1) * (y_pred > 0.5)\n",
    "index = index1 + index2\n",
    "plt.scatter(X_train[index], y_train[index], color='orange')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test loss\n",
    "X_test_2d = X_test.???\n",
    "y_pred = model.???\n",
    "\n",
    "test_loss = np.mean((y_test - y_pred)**2)\n",
    "print('Train Loss for LinearRegression model : %.4f' % test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.???\n",
    "b = model.???\n",
    "\n",
    "y_pred = 1 / (1 + np.exp(-(w*X_test + b)))\n",
    "y_pred = y_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the trained linear regression model\n",
    "plt.scatter(X_test, y_test)   # scatter the original data\n",
    "plt.scatter(X_test, y_pred, color='red')\n",
    "plt.axhline(y=0.5, color='orange', linestyle='--')   # show 0.5 threshold line\n",
    "\n",
    "# Accurate results are colored as orange\n",
    "index1 = (y_test == 0) * (y_pred < 0.5)\n",
    "index2 = (y_test == 1) * (y_pred > 0.5)\n",
    "index = index1 + index2\n",
    "plt.scatter(X_test[index], y_test[index], color='orange')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
